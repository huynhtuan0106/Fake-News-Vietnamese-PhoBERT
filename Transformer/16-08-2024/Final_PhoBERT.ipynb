{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "129VVFjQCohe"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from google.colab import files\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import EarlyStoppingCallback, AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io"
      ],
      "metadata": {
        "id": "UkFtB9jDZ25G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY6VxMziZakS",
        "outputId": "2c153265-2e46-46c9-bcb3-c7c78d947274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTwdLwV9Ewam"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "model = AutoModel.from_pretrained(\"vinai/phobert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Report1/train_data.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Report1/val_data.csv')\n",
        "\n",
        "train_texts = train_df['content']\n",
        "train_labels = train_df['label']\n",
        "val_texts = val_df['content']\n",
        "val_labels = val_df['label']"
      ],
      "metadata": {
        "id": "CecFPhvWZtGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQvjHNpUFDmL"
      },
      "outputs": [],
      "source": [
        "# Tokenize d·ªØ li·ªáu v·ªõi padding\n",
        "def tokenize_and_pad(texts, tokenizer, max_length=256):\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding='max_length',  # Th√™m padding ƒë·ªÉ t·∫•t c·∫£ c√°c vƒÉn b·∫£n c√≥ c√πng chi·ªÅu d√†i\n",
        "        max_length=max_length\n",
        "    )\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_and_pad(train_texts.tolist(), tokenizer, max_length=256)\n",
        "val_encodings = tokenize_and_pad(val_texts.tolist(), tokenizer, max_length=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1Z0omZ5SoDF"
      },
      "outputs": [],
      "source": [
        "# Tokenize\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=256, truncation_strategy='longest_first')\n",
        "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=256, truncation_strategy='longest_first')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYVLLzqGFFsn",
        "outputId": "937ef273-704e-4ca7-a71d-5bda71cd0540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "[[0, 1656, 8, 1347, 8915, 336, 5963, 2546, 620, 396, 30, 1302, 9412, 56669, 11, 197, 133, 151, 3634, 848, 99, 396, 123, 292, 336, 20014, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 2925, 474, 2515, 23523, 34, 275, 262, 829, 13351, 6425, 3635, 94, 58, 679, 103, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
            "[[0, 1901, 3345, 8474, 378, 1133, 5841, 34, 109, 2283, 2958, 10184, 2262, 574, 4567, 946, 811, 6, 3489, 426, 159, 2908, 57, 33, 11297, 2697, 63, 37, 2991, 5281, 105, 558, 7424, 1864, 510, 1690, 795, 5237, 2283, 9, 1210, 28, 15874, 385, 1510, 668, 574, 2178, 35, 76, 2262, 574, 34, 109, 2283, 2958, 10184, 630, 979, 14385, 2151, 38, 45, 2301, 1981, 2308, 1901, 701, 44, 3224, 1133, 5841, 35, 2262, 574, 2178, 32000, 192, 34, 109, 2283, 2958, 10184, 2262, 574, 4567, 946, 811, 6, 3489, 426, 10, 7328, 94, 445, 1901, 13466, 1401, 574, 2178, 309, 1659, 34234, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 18, 452, 33, 7842, 698, 5932, 1734, 27497, 43269, 12879, 7594, 115, 156, 63, 14299, 1395, 2158, 1079, 22521, 151, 462, 7902, 10, 5297, 320, 1659, 3613, 5916, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ]
        }
      ],
      "source": [
        "# Ki·ªÉm tra d·ªØ li·ªáu sau khi token h√≥a\n",
        "print(train_encodings.keys())\n",
        "print(val_encodings.keys())\n",
        "print(train_encodings['input_ids'][:2])  # Hi·ªÉn th·ªã m·ªôt v√†i m·∫´u tokenized\n",
        "print(val_encodings['input_ids'][:2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjoF8x-5QtUH"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels).astype(int)\n",
        "val_labels = np.array(val_labels).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwTStypKFHmb",
        "outputId": "15612efd-d085-4640-963c-58fddbd056a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1}\n",
            "{0, 1}\n"
          ]
        }
      ],
      "source": [
        "# Ki·ªÉm tra nh√£n\n",
        "print(set(train_labels))\n",
        "print(set(val_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S08BYmVXFJ2P"
      },
      "outputs": [],
      "source": [
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx]).squeeze()  # ƒê·∫£m b·∫£o nh√£n c√≥ k√≠ch th∆∞·ªõc ƒë√∫ng\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = FakeNewsDataset(train_encodings, train_labels.tolist())\n",
        "val_dataset = FakeNewsDataset(val_encodings, val_labels.tolist())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫£i m√¥ h√¨nh ph√¢n lo·∫°i\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca9iUrufebMz",
        "outputId": "7e35f655-2027-4ef0-b6d4-b53fc5473a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tA1mLLteFMZO",
        "outputId": "4c326c8a-47b1-4419-9507-69a80007f274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='429' max='429' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [429/429 2:42:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.706500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.714500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.696000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.693400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.687100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.667000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.648900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.615700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.600200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.548900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.564600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.445300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.453700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.478500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.441500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.433400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.438600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.509200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.411700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.445900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.399300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.357400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.486600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.406600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.469600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.315900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.327700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.279700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.294200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.195400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.257600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.219600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.380800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.174400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.263800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.356000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.407700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.256900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.239100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.423800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.457900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=429, training_loss=0.4429106942979328, metrics={'train_runtime': 9759.135, 'train_samples_per_second': 0.351, 'train_steps_per_second': 0.044, 'total_flos': 450709237831680.0, 'train_loss': 0.4429106942979328, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Thi·∫øt l·∫≠p c√°c tham s·ªë hu·∫•n luy·ªán\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Kh·ªüi t·∫°o Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# D·ª± ƒëo√°n nh√£n cho t·∫≠p ki·ªÉm tra\n",
        "predictions = trainer.predict(val_dataset)\n",
        "pred_labels = np.argmax(predictions.predictions, axis=1)"
      ],
      "metadata": {
        "id": "Gk3smAj5oCWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T√≠nh c√°c ch·ªâ s·ªë\n",
        "accuracy = accuracy_score(val_labels, pred_labels)\n",
        "precision = precision_score(val_labels, pred_labels, pos_label=0)\n",
        "recall = recall_score(val_labels, pred_labels, pos_label=0)\n",
        "f1 = f1_score(val_labels, pred_labels, pos_label=0)\n",
        "auc = roc_auc_score(val_labels, predictions.predictions[:, 1])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.6f}\")\n",
        "print(f\"Precision: {precision:.6f}\")\n",
        "print(f\"Recall: {recall:.6f}\")\n",
        "print(f\"F1 Score: {f1:.6f}\")\n",
        "print(f'AUC: {auc:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaT6dqSijFdf",
        "outputId": "ee8910ee-c677-41a2-c694-75157f710014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.881119\n",
            "Precision: 0.861111\n",
            "Recall: 0.898551\n",
            "F1 Score: 0.879433\n",
            "AUC: 0.923423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln-RjW6HTV_I",
        "outputId": "18b9d58b-fc60-4e64-c295-088aa3a017e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./saved_model/tokenizer_config.json',\n",
              " './saved_model/special_tokens_map.json',\n",
              " './saved_model/vocab.txt',\n",
              " './saved_model/bpe.codes',\n",
              " './saved_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model.save_pretrained('./saved_model')\n",
        "tokenizer.save_pretrained('./saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/Report1/PhoBERT_fakenews'\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcEPhX8qk-4a",
        "outputId": "06ff51d5-a84f-4ee9-9ee8-bb91ced8c0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab Notebooks/Report1/PhoBERT_fakenews/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/Report1/PhoBERT_fakenews/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/Report1/PhoBERT_fakenews/vocab.txt',\n",
              " '/content/drive/MyDrive/Colab Notebooks/Report1/PhoBERT_fakenews/bpe.codes',\n",
              " '/content/drive/MyDrive/Colab Notebooks/Report1/PhoBERT_fakenews/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('./saved_model')\n",
        "tokenizer = AutoTokenizer.from_pretrained('./saved_model')\n",
        "\n",
        "inputs = tokenizer(\"S·∫≠p h·∫ßm thang Qu·∫£ng Ninh con s·ªë thi·ªát m·∫°ng kh·ªïng l·ªì\", return_tensors=\"pt\")\n",
        "# Th·ª±c hi·ªán d·ª± ƒëo√°n\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# L·∫•y logits t·ª´ k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
        "logits = outputs.logits\n",
        "print(logits)\n",
        "\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi logits th√†nh x√°c su·∫•t\n",
        "probs = softmax(logits, dim=1)\n",
        "print(probs)\n",
        "\n",
        "# L·∫•y l·ªõp d·ª± ƒëo√°n (l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t)\n",
        "predicted_class = torch.argmax(probs, dim=1)\n",
        "print(predicted_class)\n"
      ],
      "metadata": {
        "id": "5_DmRERvoJYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thi·∫øt l·∫≠p c√°c tham s·ªë hu·∫•n luy·ªán (c√≥ d·ª´ng s·ªõm)\n",
        "training_args_with_early_stop = TrainingArguments(\n",
        "    output_dir='./results_with_early_stop',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs_with_early_stop',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_steps=50,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Kh·ªüi t·∫°o Trainer (c√≥ d·ª´ng s·ªõm)\n",
        "trainer_with_early_stop = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_with_early_stop,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ],
      "metadata": {
        "id": "n3JBkVY01gen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ef1002-7f42-4533-8f84-6193970c4d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_with_early_stop.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "2Hxl536E2C0l",
        "outputId": "bfe16c0e-6d38-4b2a-f8e6-77d57eb66e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='201' max='705' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [201/705 1:26:14 < 3:38:25, 0.04 it/s, Epoch 1.42/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.666900</td>\n",
              "      <td>0.649600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.608800</td>\n",
              "      <td>0.536838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.433600</td>\n",
              "      <td>0.401675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/36 00:59 < 02:50, 0.15 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='550' max='705' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [550/705 4:08:52 < 1:10:23, 0.04 it/s, Epoch 3/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.666900</td>\n",
              "      <td>0.649600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.608800</td>\n",
              "      <td>0.536838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.433600</td>\n",
              "      <td>0.401675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.476200</td>\n",
              "      <td>0.414312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.246300</td>\n",
              "      <td>0.322671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.225300</td>\n",
              "      <td>0.360279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.337800</td>\n",
              "      <td>0.591495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.328400</td>\n",
              "      <td>0.309345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.421400</td>\n",
              "      <td>0.387609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.380200</td>\n",
              "      <td>0.853271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.226300</td>\n",
              "      <td>0.409813</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=550, training_loss=0.37616828766736116, metrics={'train_runtime': 14967.261, 'train_samples_per_second': 0.375, 'train_steps_per_second': 0.047, 'total_flos': 577265655459840.0, 'train_loss': 0.37616828766736116, 'epoch': 3.900709219858156})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# D·ª± ƒëo√°n nh√£n cho t·∫≠p ki·ªÉm tra\n",
        "predictions2 = trainer_with_early_stop.predict(val_dataset)\n",
        "\n",
        "# L·∫•y nh√£n d·ª± ƒëo√°n t·ª´ logits\n",
        "pred_labels2 = np.argmax(predictions2.predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uq10TXVVROBe",
        "outputId": "693565c7-711c-4101-813b-84d60583400f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In ra m·ªôt s·ªë d·ª± ƒëo√°n ƒë·ªÉ ki·ªÉm tra\n",
        "print(pred_labels2[:10])  # In ra 10 d·ª± ƒëo√°n ƒë·∫ßu ti√™n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FYsSzRHoOWf",
        "outputId": "5a08a697-6efc-4646-b3c0-6b17855935a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 0 1 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_labels2[:])  # In ra d·ª± ƒëo√°n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHOzx4YaqbNo",
        "outputId": "eebe4cdb-da3a-4f30-9b72-b9f90bda6660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1\n",
            " 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0\n",
            " 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1\n",
            " 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0\n",
            " 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0\n",
            " 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T√≠nh c√°c ch·ªâ s·ªë\n",
        "accuracy2 = accuracy_score(val_labels, pred_labels2)\n",
        "precision2 = precision_score(val_labels, pred_labels2, pos_label=0)\n",
        "recall2 = recall_score(val_labels, pred_labels2, pos_label=0)\n",
        "f12 = f1_score(val_labels, pred_labels2, pos_label=0)\n",
        "auc2 = roc_auc_score(val_labels, predictions2.predictions[:, 1])\n",
        "\n",
        "print(f\"Accuracy: {accuracy2:.6f}\")\n",
        "print(f\"Precision: {precision2:.6f}\")\n",
        "print(f\"Recall: {recall2:.6f}\")\n",
        "print(f\"F1 Score: {f12:.6f}\")\n",
        "print(f'AUC: {auc2:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpoz-cvrTFjk",
        "outputId": "38a0ea81-3dda-45f2-b974-e9697db65b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.872340\n",
            "Precision: 0.850649\n",
            "Recall: 0.909722\n",
            "F1 Score: 0.879195\n",
            "AUC: 0.947665\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}